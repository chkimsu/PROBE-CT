{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Module Import\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gensim\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from gensim.models.fasttext import FastText as FT_gensim\n",
    "from datetime import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout, Conv1D, GlobalMaxPool1D, SimpleRNN\n",
    "from keras import backend as K\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#transport = pd.read_csv('transport_classifier_train_20191212.csv')\n",
    "\n",
    "before1hour = 'T_AD_XDR_TR_KNOWN_' + '20200121'\n",
    "\n",
    "conn = pymysql.connect(host ='192.168.6.89' , port = 3306,\n",
    "                       user = 'atom', password = 'atom', db = '5G_Probe_App_Discovery', charset = 'utf8',\n",
    "                      cursorclass = pymysql.cursors.DictCursor)\n",
    "# 커서 가져오기\n",
    "curs = conn.cursor()\n",
    "sql = \"SELECT * FROM \" + before1hour + \" WHERE OngoingFlag = 1 AND SummaryCreateTime >= unix_timestamp(date_add('2020-01-21 10:00', interval -1 hour)) AND SummaryCreateTime < unix_timestamp('2020-01-21 10-00');\"\n",
    "curs.execute(sql)\n",
    "# 데이터 가져오기\n",
    "transport = pd.DataFrame(curs.fetchall())\n",
    "transport = transport.dropna(subset = ['App_Group_Code']).reset_index(drop=True)\n",
    "transport = transport[['SummaryCreateTime', 'IMSI', 'Gender', 'Age', 'App_ID', 'App_Group_Code', 'App_Port','Protocol', 'IP_Version', 'App_IPv4', 'App_IPv6', 'DNS.QueryName', 'DNS.LastDnsTimeToLive', 'Traffic.Delta.Dnlink.DataSize', 'Traffic.Delta.Uplink.DataSize', 'TCP.Delta.MSS.SynAckMssSize', 'Traffic.Delta.Uplink.RetransPayloadSize', 'Traffic.Delta.Dnlink.RetransPayloadSize']].copy()\n",
    "\n",
    "transport.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 데이터 만들때는 app_id 개수가 5개이하인건 제외하고 생각\n",
    "#### 이상치 알고리즘에서 6개이상인것만 신경쓰도록 해야한다. 5개이하인 app_id 개수 : 156개\n",
    "#### 6개이상인 appid에 대해서 2개씩을 이상치로 놓음\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transport['new_label'] = transport['app_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "app_id\n",
       "F023     12909\n",
       "H017     13098\n",
       "C5F5     13168\n",
       "EE9F     13419\n",
       "EAD5     13514\n",
       "F021     14378\n",
       "H014     15857\n",
       "EACA     16363\n",
       "EAE6     16594\n",
       "EACC     16746\n",
       "H012     17984\n",
       "EC43     20566\n",
       "EAA9     33956\n",
       "EB16     38881\n",
       "H032     39324\n",
       "EAF0     41767\n",
       "ED08     51130\n",
       "H020     52915\n",
       "C446     79965\n",
       "EAF8    166843\n",
       "Name: index, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transport.groupby('app_id').count()['index'].sort_values()[-20: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "appid_6 = list(transport.groupby('app_id').count()['index'].sort_values()[-20: ].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(appid_6)):\n",
    "    if i < len(appid_6)-1:\n",
    "        transport.loc[list(transport[transport.app_id == appid_6[i]].iloc[-4000 : ].index)[:], 'new_label'] = appid_6[i+1]\n",
    "        transport.loc[list(transport[transport.app_id == appid_6[i]].iloc[ : -4000].index)[:], 'new_label'] = appid_6[i]\n",
    "    else : \n",
    "        transport.loc[list(transport[transport.app_id == appid_6[i]].iloc[-4000 : ].index)[:], 'new_label'] = appid_6[0] \n",
    "        transport.loc[list(transport[transport.app_id == appid_6[i]].iloc[ : -4000].index)[:], 'new_label'] = appid_6[i]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## DNS Vector화\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DNS_Encoding.data_nodns_del import data_nodns_del\n",
    "from DNS_Encoding.make_fasttext_model_vector2 import make_fasttext_model_vector2\n",
    "from DNS_Encoding.making_training_bydns import making_training_bydns\n",
    "transport_1 = data_nodns_del(transport)\n",
    "transport_vector,transport_modelinit, max_length_transport = make_fasttext_model_vector2(transport_1)\n",
    "transportdns_training = making_training_bydns(transport,transport_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## IP Vector화\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IP_Encoding.ipencoding_65536_delH import ipencoding_65536_delH\n",
    "\n",
    "transport_ip65536_delH = ipencoding_65536_delH(transport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ETC Features Vecotr화 \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data01/CSB/CSB_Jupyter/PROBE/DEMO/Etc_features/port_onehot.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  b['app_port'] = 'x'\n",
      "/data01/CSB/CSB_Jupyter/PROBE/DEMO/Etc_features/protocol_onehot.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  b['protocol'] = 'x'\n"
     ]
    }
   ],
   "source": [
    "from Etc_features.age_onehot import age_onehot\n",
    "from Etc_features.gender_onehot import gender_onehot\n",
    "from Etc_features.port_onehot import port_onehot\n",
    "from Etc_features.protocol_onehot import protocol_onehot\n",
    "from Etc_features.time_hour_onehot import time_hour_onehot\n",
    "from Etc_features.train_delta_dn_link_data_size import train_delta_dn_link_data_size\n",
    "from Etc_features.train_delta_up_link_data_size import train_delta_up_link_data_size\n",
    "from Etc_features.train_lastdnstimetolive import train_lastdnstimetolive\n",
    "from Etc_features.train_synackmsssize import train_synackmsssize\n",
    "def train_delta_dn_link_payload_size(data):\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    fitted = min_max_scaler.fit(data[['delta_dn_link_payload_size']].astype('float64'))\n",
    "    output = min_max_scaler.transform(data[['delta_dn_link_payload_size']].astype('float64'))\n",
    "    output = pd.DataFrame(output)\n",
    "    output.columns = ['delta_dn_link_payload_size']\n",
    "\n",
    "    #추가(20191023), 최종 모델링에서는 삭제해야함\n",
    "    output.index = data.index\n",
    "    return pd.DataFrame(output)\n",
    "\n",
    "def train_delta_up_link_payload_size(data):\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    fitted = min_max_scaler.fit(data[['delta_up_link_payload_size']].astype('float64'))\n",
    "    output = min_max_scaler.transform(data[['delta_up_link_payload_size']].astype('float64'))\n",
    "    output = pd.DataFrame(output)\n",
    "    output.columns = ['delta_up_link_payload_size']\n",
    "\n",
    "    #추가(20191023), 최종 모델링에서는 삭제해야함\n",
    "    output.index = data.index\n",
    "    return pd.DataFrame(output)\n",
    "\n",
    "transport_age = age_onehot(transport)\n",
    "transport_gender = gender_onehot(transport)\n",
    "transport_port = port_onehot(transport)\n",
    "transport_protocol = protocol_onehot(transport)\n",
    "transport_timehour = time_hour_onehot(transport)\n",
    "transport_lastdnstimetolive = train_lastdnstimetolive(transport)\n",
    "transport_delta_dn_link_data_size = train_delta_dn_link_data_size(transport)\n",
    "transport_delta_up_link_data_size = train_delta_up_link_data_size(transport)\n",
    "transport_synackmsssize = train_synackmsssize(transport)\n",
    "transport_train_delta_dn_link_payload_size = train_delta_dn_link_payload_size(transport)\n",
    "transport_train_delta_up_link_payload_size = train_delta_up_link_payload_size(transport)\n",
    "\n",
    "\n",
    "transport_training_ip65536_delH = pd.concat([transport_ip65536_delH, transportdns_training, transport_age, transport_gender, transport_port, \n",
    "                                        transport_protocol, transport_timehour, transport_lastdnstimetolive,transport_delta_dn_link_data_size,transport_delta_up_link_data_size,\n",
    "                                        transport_synackmsssize, transport_train_delta_up_link_payload_size, transport_train_delta_dn_link_payload_size], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_id = list(transport.groupby('app_id').count().index)\n",
    "transport_training_ip65536_delH = pd.concat([transport_training_ip65536_delH , transport[['app_id']]], axis=1)\n",
    "transport_training_ip65536_delH = pd.concat([transport_training_ip65536_delH , transport[['new_label']]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### isolation forest 1, -1\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(columns = http_training_ip65536_delH.columns)\n",
    "\n",
    "\n",
    "for i in range(len(app_id)):\n",
    "    if len(http_training_ip65536_delH[http_training_ip65536_delH.app_id == app_id[i]])<4:\n",
    "        xx = http_training_ip65536_delH.loc[list(http_training_ip65536_delH[http_training_ip65536_delH.app_id == app_id[i]].index)]\n",
    "        xx['anomaly_score'] = [2 for i in range(len(xx))]\n",
    "        a = pd.concat([a,xx])\n",
    "\n",
    "        \n",
    "###### 2는 3개이하짜리들 \n",
    "    \n",
    "    else:\n",
    "        clf = IsolationForest(n_estimators=50, contamination=0.10, random_state=35, verbose=0)\n",
    "        y_pred = clf.fit_predict(http_training_ip65536_delH[http_training_ip65536_delH.app_id == app_id[i]].drop(['app_id','new_label'], axis = 1)) #1,-1로 나온다.\n",
    "        \n",
    "        xx = http_training_ip65536_delH.loc[list(http_training_ip65536_delH[http_training_ip65536_delH.app_id == app_id[i]].index)]\n",
    "        xx['anomaly_score'] = list(y_pred)\n",
    "        a = pd.concat([a,xx])\n",
    "        \n",
    "        \n",
    "###### -1이 이상치, 1이 정상."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sum(a[a.app_id != a.new_label].anomaly_score == -1)\n",
    "y = sum(a[a.app_id != a.new_label].anomaly_score == 1)\n",
    "print('이상치 중에서 실제로 이상치로 모델이 판별한 비율 : ' + str(x/(x+y)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = sum(a[a.app_id == a.new_label].anomaly_score == -1)\n",
    "w = sum(a[a.app_id == a.new_label].anomaly_score == 1)\n",
    "print('정상 중에서 이상치로 잘못 판별한 비율 : ' + str(z/(z+w)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### isolation forest score 값\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chkimsu/anaconda3/envs/csb2/lib/python3.6/site-packages/ipykernel_launcher.py:7: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  import sys\n",
      "/home/chkimsu/anaconda3/envs/csb2/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/home/chkimsu/anaconda3/envs/csb2/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/home/chkimsu/anaconda3/envs/csb2/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/home/chkimsu/anaconda3/envs/csb2/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/home/chkimsu/anaconda3/envs/csb2/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/home/chkimsu/anaconda3/envs/csb2/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/home/chkimsu/anaconda3/envs/csb2/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/home/chkimsu/anaconda3/envs/csb2/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/home/chkimsu/anaconda3/envs/csb2/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/home/chkimsu/anaconda3/envs/csb2/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/home/chkimsu/anaconda3/envs/csb2/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/home/chkimsu/anaconda3/envs/csb2/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/home/chkimsu/anaconda3/envs/csb2/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/home/chkimsu/anaconda3/envs/csb2/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/home/chkimsu/anaconda3/envs/csb2/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/home/chkimsu/anaconda3/envs/csb2/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/home/chkimsu/anaconda3/envs/csb2/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/home/chkimsu/anaconda3/envs/csb2/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/home/chkimsu/anaconda3/envs/csb2/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "/home/chkimsu/anaconda3/envs/csb2/lib/python3.6/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "a = pd.DataFrame(columns = transport_training_ip65536_delH.columns)\n",
    "\n",
    "for i in range(len(app_id)):\n",
    "    if len(transport_training_ip65536_delH[transport_training_ip65536_delH.app_id == app_id[i]])<12909:\n",
    "        xx = transport_training_ip65536_delH.loc[list(transport_training_ip65536_delH[transport_training_ip65536_delH.app_id == app_id[i]].index)]\n",
    "        xx['anomaly_score'] = [2 for i in range(len(xx))]\n",
    "        a = pd.concat([a,xx])\n",
    "\n",
    "            \n",
    "    else:\n",
    "        clf = IsolationForest(n_estimators=50, contamination=0.30, random_state=35, verbose=0)\n",
    "        clf.fit(transport_training_ip65536_delH[transport_training_ip65536_delH.app_id == app_id[i]].drop(['app_id','new_label'], axis = 1))\n",
    "        y_pred = clf.score_samples(transport_training_ip65536_delH[transport_training_ip65536_delH.app_id == app_id[i]].drop(['app_id','new_label'], axis = 1)) #1,-1로 나온다.\n",
    "        xx = transport_training_ip65536_delH.loc[list(transport_training_ip65536_delH[transport_training_ip65536_delH.app_id == app_id[i]].index)]\n",
    "        xx['anomaly_score'] = list(y_pred)\n",
    "        a = pd.concat([a,xx])\n",
    "        \n",
    "        \n",
    "###### -1이 이상치, 1이 정상."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 개수 : 1065997\n",
      "모델이 이상치로 판별한 데이터 개수 : 85956\n",
      "데이터 실제 이상치 개수 : 80000\n",
      "이상치로 판별한 데이터 중 실제 이상치 개수 : 13002\n"
     ]
    }
   ],
   "source": [
    "print('전체 데이터 개수 : '+str(len(a)))\n",
    "print('모델이 이상치로 판별한 데이터 개수 : ' + str(len(a[a.anomaly_score<-0.45])))\n",
    "print('데이터 실제 이상치 개수 : ' + str(sum(a.app_id != a.new_label)))\n",
    "print('이상치로 판별한 데이터 중 실제 이상치 개수 : '+ str(sum(a[a.anomaly_score<-0.45].app_id != a[a.anomaly_score<-0.45].new_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 권대리님 모델에 태울 것\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http.loc[list(a[a.anomaly_score <-0.5].index)].to_csv('modelinputhttp.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csb2",
   "language": "python",
   "name": "csb2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
